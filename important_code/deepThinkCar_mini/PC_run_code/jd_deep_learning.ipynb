{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7GoF_Ls19Ny"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import fnmatch\n",
        "import datetime\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcPyIxUs2WmT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(formatter={'float_kind':lambda x: \"%.4f\" % x})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nrSWTUX2Zdf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO23ei_y2zos"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cHGGwSE28BA"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from imgaug import augmenters as img_aug\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MunDtU0g44DW"
      },
      "outputs": [],
      "source": [
        "class JdDeepLearning: \n",
        "\n",
        "    def __init__(self):\n",
        "        data_dir = 'data'\n",
        "        file_list = os.listdir(data_dir)\n",
        "        image_paths = []\n",
        "        steering_angles = []\n",
        "        pattern = \"*.png\"\n",
        "        self.model_output_dir = 'output'\n",
        "        for filename in file_list:\n",
        "            if fnmatch.fnmatch(filename, pattern):\n",
        "                image_paths.append(os.path.join(data_dir, filename))\n",
        "                angle = int(filename[-7:-4])\n",
        "                steering_angles.append(angle)\n",
        "\n",
        "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split( image_paths, steering_angles, test_size=0.2)\n",
        "        print(\"Training data: %d\\nValidation data: %d\" % (len(self.X_train), len(self.X_valid)))\n",
        "\t\n",
        "    '''\n",
        "    labeling image data augmentation \n",
        "    '''\n",
        "    # put it together\n",
        "    def random_augment(self, image, steering_angle):\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = self.pan(image)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = self.zoom(image)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = self.blur(image)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = self.adjust_brightness(image)\n",
        "        image, steering_angle = self.random_flip(image, steering_angle)\n",
        "        \n",
        "        return image, steering_angle\n",
        "\n",
        "    def my_imread(self, image_path):\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        return image\n",
        "\n",
        "    def zoom(self, image):\n",
        "        zoom = img_aug.Affine(scale=(1, 1.3))  # zoom from 100% (no zoom) to 130%\n",
        "        image = zoom.augment_image(image)\n",
        "        return image\n",
        "\n",
        "    def pan(self, image):\n",
        "        # pan left / right / up / down about 10%\n",
        "        pan = img_aug.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
        "        image = pan.augment_image(image)\n",
        "        return image\n",
        "\n",
        "    def adjust_brightness(self, image):\n",
        "        # increase or decrease brightness by 30%\n",
        "        brightness = img_aug.Multiply((0.7, 1.3))\n",
        "        image = brightness.augment_image(image)\n",
        "        return image\n",
        "    \n",
        "    def blur(self, image):\n",
        "        kernel_size = random.randint(1, 5)  # kernel larger than 5 would make the image way too blurry\n",
        "        image = cv2.blur(image,(kernel_size, kernel_size))\n",
        "    \n",
        "        return image\n",
        "\n",
        "    def random_flip(self, image, steering_angle):\n",
        "        is_flip = random.randint(0, 1)\n",
        "        if is_flip == 1:\n",
        "            # randomly flip horizon\n",
        "            image = cv2.flip(image,1)\n",
        "            steering_angle = 180 - steering_angle\n",
        "    \n",
        "        return image, steering_angle\n",
        "    \n",
        "    def img_preprocess(self, image):\n",
        "        height, _, _ = image.shape\n",
        "        image = image[int(height/2):,:,:]  # remove top half of the image, as it is not relavant for lane following\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n",
        "        image = cv2.GaussianBlur(image, (3,3), 0)\n",
        "        image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model\n",
        "        image = image / 255 # normalizing, the processed image becomes black for some reason.  do we need this?\n",
        "        return image\n",
        "\n",
        "    '''\n",
        "    Creating Convolution Neural Network \n",
        "    '''\n",
        "    def nvidia_model(self):\n",
        "        model = Sequential(name='Nvidia_Model')\n",
        "        \n",
        "        # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "        # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
        "        \n",
        "        # Convolution Layers\n",
        "        model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu')) \n",
        "        model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu')) \n",
        "        model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu')) \n",
        "        model.add(Conv2D(64, (3, 3), activation='elu')) \n",
        "        model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
        "        model.add(Conv2D(64, (3, 3), activation='elu')) \n",
        "        \n",
        "        # Fully Connected Layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
        "        model.add(Dense(100, activation='elu'))\n",
        "        model.add(Dense(50, activation='elu'))\n",
        "        model.add(Dense(10, activation='elu'))\n",
        "        \n",
        "        # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "        model.add(Dense(1)) \n",
        "        \n",
        "        # since this is a regression problem not classification problem,\n",
        "        # we use MSE (Mean Squared Error) as loss function\n",
        "        optimizer = Adam(lr=1e-3) # lr is learning rate\n",
        "        model.compile(loss='mse', optimizer=optimizer)\n",
        "        \n",
        "        return model\n",
        "\n",
        "    '''\n",
        "    Generating image for deep leanring with data augmentation\n",
        "    '''\n",
        "    def image_data_generator(self, image_paths, steering_angles, batch_size, is_training):\n",
        "        while True:\n",
        "            batch_images = []\n",
        "            batch_steering_angles = []\n",
        "            \n",
        "            for i in range(batch_size):\n",
        "                random_index = random.randint(0, len(image_paths) - 1)\n",
        "                image_path = image_paths[random_index]\n",
        "                image = self.my_imread(image_paths[random_index])\n",
        "                steering_angle = steering_angles[random_index]\n",
        "                if is_training:\n",
        "                    # training: augment image\n",
        "                    image, steering_angle = self.random_augment(image, steering_angle)\n",
        "                \n",
        "                image = self.img_preprocess(image)\n",
        "                batch_images.append(image)\n",
        "                batch_steering_angles.append(steering_angle)\n",
        "                \n",
        "            yield( np.asarray(batch_images), np.asarray(batch_steering_angles))\n",
        "    '''\n",
        "    3. deep_learning()\n",
        "    - Actual deep learning traiing method \n",
        "    '''\n",
        "    def deep_training(self):\n",
        "        '''\n",
        "        3-1. Creating CNN network based on nVIDIA model \n",
        "        '''\n",
        "        model = self.nvidia_model()\n",
        "        print(model.summary())\n",
        "\n",
        "        ncol = 2\n",
        "        nrow = 2\n",
        "\n",
        "        '''\n",
        "        3-2. Spliting labeling dataset into train data and test data  \n",
        "        '''\n",
        "        X_train_batch, y_train_batch = next(self.image_data_generator(self.X_train, self.y_train, nrow, True))\n",
        "        X_valid_batch, y_valid_batch = next(self.image_data_generator(self.X_valid, self.y_valid, nrow, False))\n",
        "\n",
        "        '''\n",
        "        3-3. Saving the model weights (inference file) after each epoch. Model is saved as name of 'lane_navigation_check.h5' at './output' folder.\n",
        "        '''\n",
        "        # saves the model weights after each epoch if the validation loss decreased\n",
        "        checkpoint_callback = ModelCheckpoint(filepath=os.path.join(self.model_output_dir,'lane_navigation_check.h5'), verbose=1, save_best_only=True)\n",
        "\n",
        "        '''\n",
        "        3-4. Performing actual deep learning training \n",
        "        '''\n",
        "        history = model.fit_generator(self.image_data_generator( self.X_train, self.y_train, batch_size=100, is_training=True),\n",
        "                                    steps_per_epoch=300,\n",
        "                                    epochs=100,\n",
        "                                    validation_data = self.image_data_generator( self.X_valid, self.y_valid, batch_size=100, is_training=False),\n",
        "                                    validation_steps=200,\n",
        "                                    verbose=1,\n",
        "                                    shuffle=1,\n",
        "                                    callbacks=[checkpoint_callback])\n",
        "\t\n",
        "        '''\n",
        "        3-5. Saving final model weight(inference file) after training is finished.  \n",
        "        '''\n",
        "        # always save model output as soon as model finishes training\n",
        "        model.save(os.path.join(self.model_output_dir,'lane_navigation_final.h5'))\n",
        "\n",
        "        '''\n",
        "        3-6. Reporting training result. \n",
        "        ''' \n",
        "        date_str = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "        history_path = os.path.join(self.model_output_dir,'history.pickle')\n",
        "        with open(history_path, 'wb') as f:\n",
        "            pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYEgr9sc54iC",
        "outputId": "cfd6ad9e-7758-4cef-e81c-bef42e642361"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data: 232\n",
            "Validation data: 58\n",
            "Model: \"Nvidia_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 31, 98, 24)        1824      \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 14, 47, 36)        21636     \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 5, 22, 48)         43248     \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 3, 20, 64)         27712     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 3, 20, 64)         0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 1, 18, 64)         36928     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 100)               115300    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                510       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 252,219\n",
            "Trainable params: 252,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-4ec424eda8da>:167: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(self.image_data_generator( self.X_train, self.y_train, batch_size=100, is_training=True),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 271.9637\n",
            "Epoch 1: val_loss improved from inf to 113.20355, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 188s 618ms/step - loss: 271.9637 - val_loss: 113.2036\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 80.6115\n",
            "Epoch 2: val_loss improved from 113.20355 to 22.97793, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 185s 618ms/step - loss: 80.6115 - val_loss: 22.9779\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 34.4613\n",
            "Epoch 3: val_loss improved from 22.97793 to 9.31523, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 185s 617ms/step - loss: 34.4613 - val_loss: 9.3152\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 18.0721\n",
            "Epoch 4: val_loss did not improve from 9.31523\n",
            "300/300 [==============================] - 187s 624ms/step - loss: 18.0721 - val_loss: 12.0863\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 13.3811\n",
            "Epoch 5: val_loss improved from 9.31523 to 8.83189, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 184s 615ms/step - loss: 13.3811 - val_loss: 8.8319\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 11.8888\n",
            "Epoch 6: val_loss did not improve from 8.83189\n",
            "300/300 [==============================] - 216s 722ms/step - loss: 11.8888 - val_loss: 9.0242\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 10.6931\n",
            "Epoch 7: val_loss improved from 8.83189 to 8.60013, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 185s 619ms/step - loss: 10.6931 - val_loss: 8.6001\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 10.6809\n",
            "Epoch 8: val_loss improved from 8.60013 to 7.62978, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 184s 616ms/step - loss: 10.6809 - val_loss: 7.6298\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 9.8561\n",
            "Epoch 9: val_loss did not improve from 7.62978\n",
            "300/300 [==============================] - 186s 620ms/step - loss: 9.8561 - val_loss: 9.4596\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 9.5156\n",
            "Epoch 10: val_loss improved from 7.62978 to 6.28398, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 184s 616ms/step - loss: 9.5156 - val_loss: 6.2840\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 8.5997\n",
            "Epoch 11: val_loss did not improve from 6.28398\n",
            "300/300 [==============================] - 216s 721ms/step - loss: 8.5997 - val_loss: 6.4029\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 8.5531\n",
            "Epoch 12: val_loss did not improve from 6.28398\n",
            "300/300 [==============================] - 215s 718ms/step - loss: 8.5531 - val_loss: 7.3459\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 8.1551\n",
            "Epoch 13: val_loss did not improve from 6.28398\n",
            "300/300 [==============================] - 215s 719ms/step - loss: 8.1551 - val_loss: 7.0388\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 7.7302\n",
            "Epoch 14: val_loss did not improve from 6.28398\n",
            "300/300 [==============================] - 185s 617ms/step - loss: 7.7302 - val_loss: 6.5335\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 7.3425\n",
            "Epoch 15: val_loss did not improve from 6.28398\n",
            "300/300 [==============================] - 184s 616ms/step - loss: 7.3425 - val_loss: 6.7953\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 6.8557\n",
            "Epoch 16: val_loss did not improve from 6.28398\n",
            "300/300 [==============================] - 186s 621ms/step - loss: 6.8557 - val_loss: 8.3803\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 6.4400\n",
            "Epoch 17: val_loss did not improve from 6.28398\n",
            "300/300 [==============================] - 215s 719ms/step - loss: 6.4400 - val_loss: 6.3822\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 6.2577\n",
            "Epoch 18: val_loss improved from 6.28398 to 6.25329, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 183s 611ms/step - loss: 6.2577 - val_loss: 6.2533\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 5.6594\n",
            "Epoch 19: val_loss did not improve from 6.25329\n",
            "300/300 [==============================] - 180s 603ms/step - loss: 5.6594 - val_loss: 7.5558\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 5.3169\n",
            "Epoch 20: val_loss improved from 6.25329 to 4.96460, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 181s 604ms/step - loss: 5.3169 - val_loss: 4.9646\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 4.9151\n",
            "Epoch 21: val_loss did not improve from 4.96460\n",
            "300/300 [==============================] - 213s 711ms/step - loss: 4.9151 - val_loss: 5.6432\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 4.7725\n",
            "Epoch 22: val_loss did not improve from 4.96460\n",
            "300/300 [==============================] - 180s 601ms/step - loss: 4.7725 - val_loss: 6.6284\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 4.5016\n",
            "Epoch 23: val_loss improved from 4.96460 to 4.36154, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 180s 602ms/step - loss: 4.5016 - val_loss: 4.3615\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 4.0648\n",
            "Epoch 24: val_loss did not improve from 4.36154\n",
            "300/300 [==============================] - 179s 600ms/step - loss: 4.0648 - val_loss: 5.2051\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 3.7958\n",
            "Epoch 25: val_loss did not improve from 4.36154\n",
            "300/300 [==============================] - 181s 605ms/step - loss: 3.7958 - val_loss: 5.5897\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 3.7644\n",
            "Epoch 26: val_loss did not improve from 4.36154\n",
            "300/300 [==============================] - 179s 597ms/step - loss: 3.7644 - val_loss: 5.2641\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 3.3450\n",
            "Epoch 27: val_loss did not improve from 4.36154\n",
            "300/300 [==============================] - 180s 602ms/step - loss: 3.3450 - val_loss: 4.4131\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 3.1526\n",
            "Epoch 28: val_loss improved from 4.36154 to 3.82978, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 180s 601ms/step - loss: 3.1526 - val_loss: 3.8298\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 3.1368\n",
            "Epoch 29: val_loss did not improve from 3.82978\n",
            "300/300 [==============================] - 181s 605ms/step - loss: 3.1368 - val_loss: 3.9593\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.9791\n",
            "Epoch 30: val_loss did not improve from 3.82978\n",
            "300/300 [==============================] - 180s 601ms/step - loss: 2.9791 - val_loss: 4.1555\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.7578\n",
            "Epoch 31: val_loss did not improve from 3.82978\n",
            "300/300 [==============================] - 180s 602ms/step - loss: 2.7578 - val_loss: 4.6891\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.6490\n",
            "Epoch 32: val_loss did not improve from 3.82978\n",
            "300/300 [==============================] - 212s 708ms/step - loss: 2.6490 - val_loss: 4.8084\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.6288\n",
            "Epoch 33: val_loss did not improve from 3.82978\n",
            "300/300 [==============================] - 212s 708ms/step - loss: 2.6288 - val_loss: 3.9638\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.6212\n",
            "Epoch 34: val_loss improved from 3.82978 to 3.73003, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 212s 708ms/step - loss: 2.6212 - val_loss: 3.7300\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.3886\n",
            "Epoch 35: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 211s 706ms/step - loss: 2.3886 - val_loss: 4.3178\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.3267\n",
            "Epoch 36: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 211s 707ms/step - loss: 2.3267 - val_loss: 4.0048\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.6872\n",
            "Epoch 37: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 181s 606ms/step - loss: 2.6872 - val_loss: 4.6866\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.2486\n",
            "Epoch 38: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 212s 707ms/step - loss: 2.2486 - val_loss: 4.8228\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.1031\n",
            "Epoch 39: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 179s 600ms/step - loss: 2.1031 - val_loss: 4.3975\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.1279\n",
            "Epoch 40: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 179s 600ms/step - loss: 2.1279 - val_loss: 4.9267\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.9636\n",
            "Epoch 41: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 180s 603ms/step - loss: 1.9636 - val_loss: 4.0475\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 2.0051\n",
            "Epoch 42: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 180s 601ms/step - loss: 2.0051 - val_loss: 4.3566\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.9507\n",
            "Epoch 43: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 214s 715ms/step - loss: 1.9507 - val_loss: 4.2569\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.8438\n",
            "Epoch 44: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 181s 604ms/step - loss: 1.8438 - val_loss: 4.2958\n",
            "Epoch 45/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.7767\n",
            "Epoch 45: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 213s 711ms/step - loss: 1.7767 - val_loss: 4.4928\n",
            "Epoch 46/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.7726\n",
            "Epoch 46: val_loss did not improve from 3.73003\n",
            "300/300 [==============================] - 183s 610ms/step - loss: 1.7726 - val_loss: 4.8793\n",
            "Epoch 47/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.6786\n",
            "Epoch 47: val_loss improved from 3.73003 to 3.69527, saving model to output/lane_navigation_check.h5\n",
            "300/300 [==============================] - 183s 610ms/step - loss: 1.6786 - val_loss: 3.6953\n",
            "Epoch 48/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.6973\n",
            "Epoch 48: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 183s 611ms/step - loss: 1.6973 - val_loss: 4.4530\n",
            "Epoch 49/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 1.6643\n",
            "Epoch 49: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 214s 714ms/step - loss: 1.6643 - val_loss: 4.5570\n",
            "Epoch 50/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 878.5124\n",
            "Epoch 50: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 183s 611ms/step - loss: 878.5124 - val_loss: 15.7248\n",
            "Epoch 51/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 21.5267\n",
            "Epoch 51: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 182s 610ms/step - loss: 21.5267 - val_loss: 7.1800\n",
            "Epoch 52/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 14.9811\n",
            "Epoch 52: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 182s 609ms/step - loss: 14.9811 - val_loss: 7.7627\n",
            "Epoch 53/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 15.9193\n",
            "Epoch 53: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 214s 716ms/step - loss: 15.9193 - val_loss: 8.5297\n",
            "Epoch 54/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 11.8424\n",
            "Epoch 54: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 182s 609ms/step - loss: 11.8424 - val_loss: 8.0642\n",
            "Epoch 55/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 9.4495\n",
            "Epoch 55: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 181s 605ms/step - loss: 9.4495 - val_loss: 7.1005\n",
            "Epoch 56/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 8.0911\n",
            "Epoch 56: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 213s 714ms/step - loss: 8.0911 - val_loss: 6.9151\n",
            "Epoch 57/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 7.3870\n",
            "Epoch 57: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 181s 605ms/step - loss: 7.3870 - val_loss: 5.7784\n",
            "Epoch 58/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 6.8913\n",
            "Epoch 58: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 183s 612ms/step - loss: 6.8913 - val_loss: 5.2521\n",
            "Epoch 59/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 6.5344\n",
            "Epoch 59: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 214s 716ms/step - loss: 6.5344 - val_loss: 5.1661\n",
            "Epoch 60/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 6.4016\n",
            "Epoch 60: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 213s 713ms/step - loss: 6.4016 - val_loss: 5.1656\n",
            "Epoch 61/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 6.4303\n",
            "Epoch 61: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 183s 612ms/step - loss: 6.4303 - val_loss: 4.5177\n",
            "Epoch 62/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 5.8147\n",
            "Epoch 62: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 214s 716ms/step - loss: 5.8147 - val_loss: 4.6989\n",
            "Epoch 63/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 5.8108\n",
            "Epoch 63: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 185s 618ms/step - loss: 5.8108 - val_loss: 6.0735\n",
            "Epoch 64/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 6.2497\n",
            "Epoch 64: val_loss did not improve from 3.69527\n",
            "300/300 [==============================] - 184s 614ms/step - loss: 6.2497 - val_loss: 4.9907\n",
            "Epoch 65/100\n",
            "228/300 [=====================>........] - ETA: 31s - loss: 5.7080"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    jdlab = JdDeepLearning()\n",
        "    jdlab.deep_training()\n",
        "    print(\"Deep learinig training finished!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}